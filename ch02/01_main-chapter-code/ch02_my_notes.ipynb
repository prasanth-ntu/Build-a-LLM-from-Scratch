{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"../images/three-main-stages-of-coding-an-llm-stage1-step1.png\" width=\"800px\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Understanding word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "<b>Why do we need embeddings?</b>\n",
    "- <span style=\"color:red\">Deep neural network (NN) models, including LLMs cannot process text data directly. Since, the text data is categorical, it's not compatible with mathematical operations used to train NNs.</span>\n",
    "- So, we need a way <span style=\"color:#4ea9fb\">to represent non numeric data (words/text) in a continuous numbers, a format that NNs can understand and process</span>.\n",
    "\n",
    "<b>What's an embedding?</b>\n",
    "- The concept of <span style=\"color:#4ea9fb\"><b>converting text (or other data) into numerical vector representations.</b></span>\n",
    "- In other words, embedding is a mapping from discrete objects (words, image, or entire documents) into a point in coninuous space. \n",
    "\n",
    "<b>Different type of embeddings</b>\n",
    "- While *word embeddings* are the most common form of tet embedding, there are other type of embeddings such as subword/token, sentence, paragraph, document, etc.\n",
    "  - Since GPT-like LLMs learn to generate one word at a time, we will focus on **word embeddings**.\n",
    "- Refer [https://prasanth.io/Knowledge/Tech/Embeddings](https://prasanth.io/Knowledge/Tech/Embeddings) for different type of embeddings.\n",
    "- For *retrieval-augmentated generation*, sentence or paragraph embeddings are more popular choices.\n",
    "\n",
    "<b>How to embed different data types?</b>\n",
    "- Using a specific NN layer or another pretrained NN model, we can embed different data types - such as text, image, video, etc. \n",
    "<p style=\"color:black; background-color:#F5C780; padding:15px\">ðŸ’¡Different data types require different embedding models. <span style=\"color:red\">Embedding model designed for text data would not be suitable for embedding audio or video data.</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"../images/different-embedding-models-for-different-data-types.png\" width=\"800px\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Word2Vec</i> - Most popular word embedding</b>\n",
    "- <span style=\"color:#4ea9fb\">The main idea behind Word2Vec is that <b>words that appear in similar contexts tend to have similar meanings</b></span>. Consequently, when projected into two-dimensional word embeddings for visualization purposes, similar terms are clustered together.\n",
    "- For more details, refer [https://prasanth.io/Knowledge/Tech/Word2Vec](https://prasanth.io/Knowledge/Tech/Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Why don't we use <i>Word2Vec</i> for LLMs?</b>\n",
    "- <span style=\"color:#4ea9fb\">LLMs commonly produce their own embeddings as part of the input layer, and are updated during training</span>.\n",
    "- <span style=\"color:green\">The advantage of optimizing the embeddings as part of the LLM training is that the embeddings are optimized to the specific data and task at hand</span>.\n",
    "  - LLMs can also create contextualized output embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What's an optimal Embedding Size</b>?\n",
    "- It's <span style=\"color:#4ea9fb\">a trade off between performance and effficiency</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qwqww"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_10_build_llm_form_scratch",
   "language": "python",
   "name": "py_3_10_build_llm_form_scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
